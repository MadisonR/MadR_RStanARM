Bayesian Regression Models with RStanARM
========================================================
author: Tristan Mahr
date: Sept. 21, 2016
autosize: true
incremental: true



Overview
========================================================

- How I got into Bayesian statistics
- Some intuition-building about Bayes theorem
- Tour of RStanARM
- Where to learn more about Bayesian statistics



August 2015: The "Crisis" in Psychology
========================================================
left: 50%

[Open Science Collaboration (2015)](http://science.sciencemag.org/content/349/6251/aac4716) tries to replicate 100 studies published in 3 psychology different journals in 2008.

![Scatter plot of original vs replicated effect sizes](./assets/reproducibility.PNG)

***

- Boil a study down to 1 effect size and 1 test statistic.
  - Compare replication's test statistic and magnitude of effect size against original.
- Approximately 36% of the studies are replicated.
- On average, the effect size in the replication is half that of the original study.



Reactions
========================================================

We're doomed.

![](./assets/throne-of-lies.gif)

Most findings are probably false.

***

No, this is business as usual.

![](./assets/business-as-usual.gif)

Any credible discipline has to do this kind of house-cleaning from time to time.




Lots of hand-wringing and soul-searching
=============================================

Some reactionary:

- Replication creates an [industry for incompetent hacks](http://www.sciencedirect.com/science/article/pii/S002210311600007X).
- Here come the [methodological terrorists](http://andrewgelman.com/2016/09/21/what-has-happened-down-here-is-the-winds-have-changed/)!

![](./assets/dumpster-fire.gif)

***

Some constructive:

- What does a failed replication even mean?
- [Everything is f'ed](https://hardsci.wordpress.com/2016/08/11/everything-is-fucked-the-syllabus/) -- so what else is new?



I'm in the business-as-usual camp, by the way
========================================================

Better research practices are catching on.

- Pre-registration
- Power analyses and [other foresight](http://www.johndcook.com/blog/2010/05/13/statistical-autopsy/).
- Meta-analytic tools to assess the health of a field
- Better disclosure of other unanalyzed measurements


Crisis made me think more of questionable data analysis practices
========================================================

Basically, unintentional acts and rituals to appease Statistical Significance gods.

- HARKing (hypothesizing after results are known)
  - Telling a story to fit the data.
- Garden of forking data
  - Conducting countless sub-tests and sub-analyses on the data
- p-hacking
  - Doing these tests in order to find a significant effect.
- Selective reporting
  - Reporting only the tests that yielded a significant result.






My response to the crisis
========================================================

- Most of my work analyzes already collected data, so I want to avoid these errors.
- I want to level up my stats and explore new techniques.
  - Maybe more robust estimation techniques
  - Maybe machine learning techniques to complement conventional analyses.
- I want something less finicky than statistical significance.
  - p-values don't mean what many people think they mean.
  - Neither do confidence intervals.
  - Statistical significance is not related to practical significance.



December 2015
========================================================

- I started reading the Gelman and Hill book.
  - This is the book for the `arm` package.
- It emphasizes estimation, uncertainty and simulation.
- Midway through, the book pivots to Bayesian estimation.
- I roll with it.

***

![](./assets/arm.jpeg)



ARM
========================================================
title: false

- I try to download the example BUGS scripts, but the page no longer has them...

> Use Stan instead.

- Okay, I'll give it try...


January 2016
========================================================

I'm down the rabbit hole, writing Stan models to fit the models from the ARM
book, and there is an influx of Bayesian tools for R.

- [Statistical Rethinking](http://xcelab.net/rm/statistical-rethinking/), a book that reteaches regression from a Bayesian perspective with R and Stan, is released (12/2015).
- A new version of [brms](https://cran.r-project.org/web/packages/brms/index.html) is released (1/2016). This package converts R model code into Stan programs.
- [RStanARM](https://cran.r-project.org/web/packages/rstanarm/index.html) is released (1/2016).
- There is a blog post called ["R Users Will Now Inevitably Become Bayesians"](https://thinkinator.com/2016/01/12/r-users-will-now-inevitably-become-bayesians/)

I eat all this up. I become a convert.


Long story short
========================================================

The crisis sparked my curiosity, and a bunch of new tools and resources made it
really easy to get started with Bayesian stats.


